{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_susy = pd.read_csv('heart.csv', engine='c')\n",
    "df_susy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pronto!\n"
     ]
    }
   ],
   "source": [
    "X=df_susy[['age', 'sex', 'cp', 'trestbps',  'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]\n",
    "# Labels\n",
    "y=df_susy['target']\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                          random_state=100,\n",
    "                                                          shuffle=True,\n",
    "                                                          stratify=y)\n",
    "print(\"Pronto!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pronto!\n"
     ]
    }
   ],
   "source": [
    "#Extend from sklearn.base BaseEstimator, ClassifierMixin\n",
    "# import threading\n",
    "# from joblib import Parallel, delayed\n",
    "class BaseEnginnering(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_subset(self, X, y, columns):\n",
    "        from pandas import DataFrame\n",
    "\n",
    "        #if not isinstance(self, X, DataFrame):\n",
    "            #raise TypeError('Expected value should descend from pandas.core.frame.DataFrame')\n",
    "            \n",
    "        df_tmp = X.copy()\n",
    "        df_tmp.insert(loc=(len(df_tmp.columns)), column='target', value=y)\n",
    "        \n",
    "        #df_subset = (df_tmp[df_tmp.columns in columns], df_tmp['target'])\n",
    "        df_subset = (df_tmp.loc[:, columns], df_tmp['target'])\n",
    "        \n",
    "        return df_subset\n",
    "    \n",
    "    def arrangement_features(self, features: list,  n_selected: int) -> list:\n",
    "        from itertools import combinations\n",
    "        permsList = list(combinations(features, r=n_selected))\n",
    "        \n",
    "        return permsList\n",
    "\n",
    "print('Pronto!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pronto!\n"
     ]
    }
   ],
   "source": [
    "class ClassifierEnginneringForest(BaseEnginnering):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.criterion = 'entropy'\n",
    "        self.splitter='best'\n",
    "        self.max_depth=None\n",
    "        self.min_samples_split=2\n",
    "        self.min_samples_leaf=1\n",
    "        self.min_weight_fraction_leaf=0\n",
    "        self.max_features=None\n",
    "        self.random_state = 200\n",
    "        self.max_leaf_nodes=None\n",
    "        #min_impurity_decrease=0,\n",
    "        #min_impurity_split=1e-7,\n",
    "        self.class_weight=None\n",
    "        self.presort=False\n",
    "        \n",
    "    def make_base_estimator(self):\n",
    "        clf = DecisionTreeClassifier(self.criterion)\n",
    "        return clf\n",
    "    \n",
    "    def make_lote_base_estimator(self):\n",
    "        pass\n",
    "    \n",
    "print('Pronto!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pronto!\n"
     ]
    }
   ],
   "source": [
    "class EnginneringForest(ClassifierEnginneringForest):\n",
    "\n",
    "    def __init__(self, select_features):\n",
    "        # Global variables\n",
    "        self.estimators_ = []\n",
    "        self.select_features_ = select_features\n",
    "        self.group_features = []\n",
    "        self.vector_predict = []\n",
    "        super().__init__()\n",
    "        \n",
    "    def build(self, features_set):\n",
    "        # Aqui vai o código para criar a floresta\n",
    "        # cria o vetor dos subconjuntos\n",
    "        # cria as instâncias das arvores\n",
    "        self.group_features = self.arrangement_features(features=features_set, n_selected=self.select_features_)\n",
    "        #self.estimators_ = [self.make_base_estimator() for item_set in self.group_features]\n",
    "        for i in self.group_features:\n",
    "            self.estimators_.append(self.make_base_estimator())\n",
    "            \n",
    "    def voting(self):\n",
    "        final_predict = []\n",
    "        for i in range(len(self.vector_predict[0])):\n",
    "            column_predict = []\n",
    "            for j in range(len(self.estimators_)):\n",
    "                column_predict.append(self.vector_predict[j][i])\n",
    "            if column_predict.count(1) > column_predict.count(0):\n",
    "                final_predict.append(1)\n",
    "            else:\n",
    "                final_predict.append(0)\n",
    "        return final_predict\n",
    "                \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "         # Determine output settings\n",
    "        n_samples, self.n_features_ = X.shape\n",
    "        name_features = X.columns\n",
    "        \n",
    "        # Cria a floresta\n",
    "        self.build(features_set=name_features)\n",
    "        \n",
    "        # Treina as arvores individualmente\n",
    "        for subset_feature, estimators in zip(self.group_features, self.estimators_):\n",
    "            subset_xdata, subset_ydata = self.get_subset(X, y, subset_feature)\n",
    "            estimators = estimators.fit(subset_xdata, subset_ydata)\n",
    "        \n",
    "        # Treina a floresta\n",
    "        #for item_set, clf in zip(self.group_features, self.estimators_):\n",
    "         #   subset_xdata, subset_ydata = self.get_subset(X, y, item_set)\n",
    "         #   clf = clf.fit(subset_xdata, subset_ydata)\n",
    "        #for subset_feature in subsets_features:\n",
    "         #   subset_xdata, subset_ydata = self.get_subset(X, y, subset_feature)\n",
    "         #   clf = self.build()\n",
    "         #   clf = clf.fit(subset_xdata, subset_ydata)\n",
    "         #   self.estimators_.append(clf)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        for subset_feature, estimators in zip(self.group_features, self.estimators_):\n",
    "            subset_test = X.loc[:, subset_feature]\n",
    "            self.vector_predict.append(estimators.predict(subset_test))\n",
    "        return self.voting()\n",
    "            \n",
    "\n",
    "print('Pronto!')\n",
    "# usar map para percorrer o vetor de arvores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnginneringForest(select_features=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8461538461538461\n",
      "\n",
      "Classifcation Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82        41\n",
      "           1       0.83      0.90      0.87        50\n",
      "\n",
      "    accuracy                           0.85        91\n",
      "   macro avg       0.85      0.84      0.84        91\n",
      "weighted avg       0.85      0.85      0.85        91\n",
      "\n",
      "\n",
      "Accuracy Score\n",
      "0.8461538461538461\n",
      "\n",
      "Confusion Matrix\n",
      "[[32  9]\n",
      " [ 5 45]]\n"
     ]
    }
   ],
   "source": [
    "mac = metrics.accuracy_score(y_test, y_pred)\n",
    "mcr = classification_report(y_test,y_pred)\n",
    "mas = accuracy_score(y_test, y_pred)\n",
    "mcm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(\"Accuracy:\", mac)\n",
    "\n",
    "print(\"\\nClassifcation Report\")\n",
    "print(mcr)  \n",
    "\n",
    "print(\"\\nAccuracy Score\")\n",
    "print(mas)\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(mcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8461538461538461\n",
      "\n",
      "Classifcation Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82        41\n",
      "           1       0.83      0.90      0.87        50\n",
      "\n",
      "    accuracy                           0.85        91\n",
      "   macro avg       0.85      0.84      0.84        91\n",
      "weighted avg       0.85      0.85      0.85        91\n",
      "\n",
      "\n",
      "Accuracy Score\n",
      "0.8461538461538461\n",
      "\n",
      "Confusion Matrix\n",
      "[[32  9]\n",
      " [ 5 45]]\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators= 100,\n",
    "                                  criterion='entropy',\n",
    "                                  max_features = 'auto',\n",
    "                                  max_depth = None,\n",
    "                                  min_samples_split = 2,\n",
    "                                  min_samples_leaf = 1,\n",
    "                                  min_weight_fraction_leaf = 0,\n",
    "                                  max_leaf_nodes = None,\n",
    "                                  min_impurity_decrease = 0,\n",
    "                                  bootstrap = True,\n",
    "                                  oob_score = True,\n",
    "                                  n_jobs = -1,\n",
    "                                  random_state = 100,\n",
    "                                  verbose = 1,\n",
    "                                  warm_start = False,\n",
    "                                  class_weight = None)\n",
    "mrf_fit = model_rf.fit(X_train, y_train)\n",
    "y_pred = model_rf.predict(X_test)\n",
    "mac = metrics.accuracy_score(y_test, y_pred)\n",
    "mcr = classification_report(y_test,y_pred)\n",
    "mas = accuracy_score(y_test, y_pred)\n",
    "mcm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(\"Accuracy:\", mac)\n",
    "\n",
    "print(\"\\nClassifcation Report\")\n",
    "print(mcr)  \n",
    "\n",
    "print(\"\\nAccuracy Score\")\n",
    "print(mas)\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(mcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimators_[0].predict(X_test.loc[:, model.group_features[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimators_[1].predict(X_test.loc[:, model.group_features[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vector_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.loc[['age', 'sex', 'cp']].iloc[0]\n",
    "X_test.loc[214, ['age', 'sex', 'cp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.estimators_:\n",
    "    print(p.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def predict(self, X):\n",
    "        # Só pode fazer a predição com os atributos usado para treinar a arvore\n",
    "        # Senão dá erro\n",
    "        #x_length = X.shape[0]\n",
    "        for item in X.index:\n",
    "            x_predict = []\n",
    "            for subset_feature, estimators in zip(self.group_features, self.estimators_):\n",
    "                subset_test = X.loc[item, subset_feature]\n",
    "                x_predict.append(estimators.predict(subset_test))\n",
    "            self.vector_predict.append(x_predict)\n",
    "            x_predict.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
